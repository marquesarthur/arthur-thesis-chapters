\setcounter{chapter}{2}


\chapter{Characterizing Task-relevant Text}
\label{ch:characterizing}



In the last chapter,
we described several studies that analyze text in software engineering artifacts
and many approaches that attempt to automatically extract relevant information from
these natural language artifacts.


Although certainly valuable,
we have established that
most of these studies focus on specific kinds of artifacts.
If we seek to design
techniques that automatically determine relevance regardless of an artifact's type,
we must determine
whether
there is consistency in the text
that software developers identify as relevant to a task across
different kinds of artifacts, and if there is consistency, we also ask
what are common relevance cues in the portions of
the text identified as task-relevant?





To answer these questions, 
this chapter presents an
\textit{empirical study} in which we asked 20 participants with
software development experience to identify relevant text within
selected artifacts for six distinct software development tasks.
We analyze the text that participants considered relevant 
to gain insight into properties of the text 
that are indicative of its relevance to a task~\cite{das2014frame, jurafsky2014speech}. 
We also report the participants'
reasoning process for determining relevance,
which we gathered through interviews
that we use to identify
common themes about their approaches~\cite{spencer2009sorting}.



We start by presenting the research questions that guide 
the design of our study (Section~\ref{cp3:method}).
We then detail experimental procedures (Section~\ref{cp3:experiment}) 
and results (Section~\ref{cp3:results}),
concluding the chapter with a summary of our findings (Section~\ref{cp3:summary}).



% \input{sections/cp3/research-questions.tex}
% \input{sections/cp3/experiment.tex}
% \input{sections/cp3/results.tex}
% \input{sections/cp3/summary.tex}



% \clearpage

% H18-02104

% 	Task Knowledge Extraction