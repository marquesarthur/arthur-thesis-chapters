
\section{Design}
\label{cp6:design}



Figure~\ref{fig:tool-experiment-procedures} summarizes our experiment.
We randomly assign two tasks to each participant in the experiment
ensuring that each task is performed with or without tool support evenly.
On their own time and computer\footnote{Literature, e.g.,~\cite{wohlin2012} or~\cite{DeLucia2012}, define this as an \textit{offline} experiment}, 
each participant performed a task where they indicated 
what text they deemed relevant to the task at hand, i.e., \textit{manual task},
and one where our tool highlighted the text identified by 
the semantic-based approach, i.e., \textit{tool-assisted task}.



The experiment's independent variable represents the task configuration, \textit{manual} or \textit{tool-assisted} tasks. Each participant is exposed to both conditions, i.e., they perform 
a first task without tool support and then, a different task with tool support.
Provided that we analyze the performance of the tasks across conditions, 
our experiment follows a \textit{between-groups} design~\cite{Lazar2017-cp3, wohlin2012}.







% \subsection{Procedures}
% \label{cp6:evaluation-procedures}



% The experiment was completely offline, i.e., it could be performed at a participant's personal computer
% without the presence of one of the researchers. Each participant had to complete a practice task---separated from the experimental tasks---and two tasks (manual and tool-assisted) drawn from the tasks in Table~\ref{tbl:python-tasks-modules}. 


% Each experimental session lasted no more than two hours; this length of time was selected based on two pilot sessions. 
% Feedback from these pilots also helped to refine the experiment's instructions, where we included a short video showing how to install the web browser plugin and how to use Colab, the online environment where participants performed each task (Section~\ref{cp6:environment}).






% We began each session gathering consent and requesting participants to install a web browser plugin which we used to gather data.
% Setup was followed by a short tutorial explaining the experiment and describing how to use the plugin and Colab. 
% The practice task allowed participants to familiarize themselves with the content of a task, the web browser plugin and Colab. 



% For each task, including the practice tasks, we asked a participant to write a solution for the task
% when provided with a fixed set of artifacts, e.g., official API documentation, Stack Overflow posts, or web tutorials, 
% associated with that task.  


% In the control task, a participant was instructed to use the web browser plugin to highlight any text that they deemed relevant to the task-at-hand. 
% \gm{Do they highlight text as they
% work or after the task?}
% In the tool assisted task, the plugin automatically highlighted sentences that our semantic-based technique identified as relevant for the task. 
% For this second task, we had one extra step asking the participant to rate---using a Likert scale---how helpful were the highlights automatically identified per artifact available. 
% \gm{More detail about exactly
% what participants were asked to
% do and experimental materials
% should be published or in Appendix
% of thesis.}


% We concluded the study by asking participants if they would like to provide any additional information and 
% by giving them the opportunity to join the raffle, if so they wished. 



% % \subsubsection{Summary of procedures}

% % Based on our experimental procedures, we could gather:



% % \begin{enumerate}
% %     \item a participant's submitted solution (written Python code) for each task;
% %     \item a participant's highlights for the control task; 
% %     \item a participant's perception on the usefulness of the automatically identified highlights for the tool assisted task, and;
% %     \item any additional feedback (written text) that a participant wished to provide us.
% % \end{enumerate}




% \clearpage


% \subsection{Analysis}



% Table~\ref{tbl:experiment-data} summarizes the data we collected based on experimental procedures.
% We use the gathered data to investigate our main hypotheses according to the following metrics.



% \input{sections/cp6/tbl-summary-of-procedures.tex}


% \subsubsection{Submitted Solution}


% % \smallskip
% % According to this definition, 


% \subsubsection{Manual Highlights}



% \subsubsection{Usefulness of the Automatic Highlights}



% % This analysis complements the quantitative comparison of manual and automatic highlights.
% % By asking participants to reflect on the usefulness of the text automatically identified, 
% % we seek to minimize risks related to how a participant might have missed highlighting
% % text that assisted them complete a task~\cite{easterbrook2008}.






% \clearpage

