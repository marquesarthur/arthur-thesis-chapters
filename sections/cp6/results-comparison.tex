\clearpage


\subsection{Comparison of the Task-relevant Text Identified}
\label{cp6:comparison}


To assist a developer correctly complete a task, a tool that
automatically identifies task-relevant text would ideally 
identify text that humans have also considered as relevant to a particular task. 
This lead us to compare the participants' manual highlights against the ones 
identified by semantic-based technique applied by the tool in our study.
 



Analogous to the evaluation procedures of Chapter~\ref{ch:identifying}, we use 
\textit{precision} and \textit{recall} metrics
to compare human and tool identified task-relevant text.




Precision measures the fraction of the automatically identified text of an artifact that was  considered relevant
by the participants. 
In turn, recall represents how many of all the manual highlights of an artifact were identified by the semantic-based technique that we applied.

\smallskip
\begin{small}


\begin{equation}
    Precision = \frac{
        \text{\textit{automatic highlights}~} \cap 
        \text{~\textit{manual highlights}}
    }{\text{\textit{automatic highlights}}}
\end{equation}
\end{small}


% \smallskip
\begin{small}
\begin{equation}
    Recall = \frac{
        \text{\textit{automatic highlights}~} \cap 
        \text{~\textit{manual highlights}}
    }{\text{\textit{manual highlights}}}
\end{equation}
\end{small}

\medskip




\input{sections/cp6/tbl-comparison-overall}


\input{sections/cp6/tbl-comparison-per-artifact-type}





% \art{Discuss how to account for variability in what the participants highlighted}

