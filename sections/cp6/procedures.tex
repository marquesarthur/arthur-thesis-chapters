
\section{Procedures}
\label{cp6:procedures}





In this section, we detail the instructions provided to the participants so that 
they could perform our experiment. 
First, we present an overview of the whole experiment and then, we detail
instructions specific to the manual and tool-assisted tasks, respectively.



We advertised the experiment via mailing lists. The email disclosed the purpose of the experiment, how long we estimated that it would take to complete it, as well as a link 
to a web survey containing the experiment's consent form and tasks. 




Once a participant consented to participate, we gathered demographics (Figure~\ref{fig:experiment-demographics}) to ensure that participants had the necessary background to perform our experiment. For example, we would discard data from a 2nd year student, someone with no experience in Object-Oriented programming languages, or that did not consult API documentation when performing a programming task. No participants were excluded based on demographics.


\input{sections/cp6/tbl-demographics.tex}


Next, the online survey gave participants further instructions 
about how to perform each task and it requested them to install \acs{beskar}.
Setup was followed by a short practice task---separate from the experimental tasks---that allowed participants to familiarize themselves with the content of a task, the tool, and coding environment that we used (Colab). 



Once a participant completed the practice task, the survey randomly assigned to them a \textit{manual} task, which was followed by a randomly assigned \textit{tool-assisted} tasks---different from the manual task. While tasks were randomly assigned, we made sure that an even number of participants attempted a task with and without tool support.
For each task, including the practice tasks, the survey provided to the participants a link 
to the task description (Figure~\ref{fig:nytimes-task-github}) and asked them to submit a solution in the form of written Python code for the task. Sections~\ref{cp6:procedures-manual} and~\ref{cp6:procedures-tool-assisted}
detail procedures specific to the manual and tool-assisted task, respectively.


Once a participant submitted their solutions, the survey
asked them about any additional feeback that they wished to share and 
offered them the opportunity to enter a raffle for one of two iPads 64 GB 
to compensate them for their time.
% The survey concluded thanking participants for their participation.



\subsection{Manual Task}
\label{cp6:procedures-manual}



In the \textit{manual} task, we instrumented \acs{beskar} to allow participants to highlight text that they deemed useful for the task at hand. 





a participant was instructed to use the web browser plugin to highlight any text that they deemed relevant to the task-at-hand. 
\gm{Do they highlight text as they
work or after the task?}

\subsection{Manual Task}
\label{cp6:procedures-tool-assisted}


In the tool assisted task, the plugin automatically highlighted sentences that our semantic-based technique identified as relevant for the task. 
For this second task, we had one extra step asking the participant to rate---using a Likert scale---how helpful were the highlights automatically identified per artifact available. 
\gm{More detail about exactly
what participants were asked to
do and experimental materials
should be published or in Appendix
of thesis.}


We concluded the study by asking participants if they would like to provide any additional information and 
by giving them the opportunity to join the raffle, if so they wished. 



\subsection{Summary}



Table~\ref{tbl:experiment-data} summarizes the data we collected based on experimental procedures.


\input{sections/cp6/tbl-summary-of-procedures.tex}



% \clearpage


% \subsection{Analysis}






% \subsubsection{Submitted Solution}


% % \smallskip
% % According to this definition, 


% \subsubsection{Manual Highlights}



% \subsubsection{Usefulness of the Automatic Highlights}



% % This analysis complements the quantitative comparison of manual and automatic highlights.
% % By asking participants to reflect on the usefulness of the text automatically identified, 
% % we seek to minimize risks related to how a participant might have missed highlighting
% % text that assisted them complete a task~\cite{easterbrook2008}.






% \clearpage

