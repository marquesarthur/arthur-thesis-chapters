\section{Approach}
\label{cp5:approaches}





Our goal is to design an \textit{artifact-agnostic} approach
to identify sentences relevant to a task in an artifact pertinent to that task.
We formulate this goal as an extractive query-based summarization problem~\cite{Goldsteinet1999}.
That is, given a query (i.e., a software task),
and a natural language software artifact as inputs,
identify a number of sentences from the input artifact that
most likely contain information relevant to that task. 
We provide details about steps towards this goal
in a top-down manner, i.e., we first introduce general concepts
used to produce a summary and then, we describe
the \textit{textual features} from related work and of our own used to identify task-relevant sentences.




\subsection{Summary Generation}


LexRank~\cite{Erkan2004} is the backbone of our approach. 
It is based on the PageRank~\cite{Page1999} algorithm
and, on its most simplistic form, LexRank threats each sentence in an artifact as a node.
Then, the algorithm
establishes edges between all the node pairs using a similarity function, ultimately producing a graph. 
The more edges a node has, more central the node is to the graph and the more likely it is that the sentence 
which that node represents contains key information. 
Thus, we can obtain a summary of the content of a pertinent artifact selecting the $n$ most central nodes of the graph. 
% To produce the summary, we select the $n$ nodes with the highest number of edges. 


To include information about a task, one can build a bipartite graph.
A first set of nodes represent sentences originating from a task while a second set, sentences in a pertinent artifact.
This time,  a similarity function 
establishes edges only  between the nodes of each one of the sets, i.e., edges from nodes in the artifact to nodes in the task.
By focusing our attention to the nodes (or sentences) with the most edges belonging to the pertinent artifact set, we can produce a summary with information relevant to that task.
% That is, the more edges a node in the set has, the more it relates to the input task and thus, that 
% it contains information . 




At this point, it is noticeable that the similarity function used by the algorithm 
is the stepping stone for determining the summary's output.  
To devise a similarity function that accounts for the richness of data available in the 
text, we base our approach on Ponzanelli el al.'s meta-information model~\cite{Ponzanelli2015}.
This model 
defines a similarity function that uses a set of properties 
or features to compute similarity and thus, establish edges in the graph.
The overall similarity value of the model is the 
normalized sum of similarity values for each individual feature or property.

% has been used in subsequent studies
% Cosine similarity using term-frequency inverse-document-frequency (\textit{tf-idf})
% vectors of the text in a task and a pertinent artifact
% is a simple 

\art{Provide formulas/formal definitions once we've agreed upon approach/chapter outline}

\subsection{Textual Features}



To devise an artifact-agnostic similarity function, we need a set of features that apply to the different artifact types a developer might seek information as part of their task.
Due to this need, we identify features that do not rely on artifact-specific data in existing related work. 
We also define new features based 
on heuristics derived from annotations from 20 participants of text deemed relevant
for the six tasks of the \acs{DS-synthetic} corpus.
Table~\ref{tbl:approach-textual-features} groups features based on the textual properties that they rely on. Details for each feature are discussed in the remainder of this section.



\art{Expand section detailing features from Table~\ref{tbl:approach-textual-features}}


\input{sections/cp5/tbl-textual-features}


\subsection{Implementation}



% to summarize software artifacts usually using artifact-specific properties~\cite{Xu2017, Li2018}.





% In a later work, they use this model to 
% help developers navigate through the artifacts retrieved in a Web search~\cite{Ponzanelli2017}.
% Orthogonal to Ponzanelli et al.~\cite{Ponzanelli2015},
% the same concept has been used by Xu et al. to 
% select relevant and
% salient sentences  in a Stack Overflow answer for summarization.






% We present an approach to automatically detect task-relevant text in a \textit{artifact-agnostic} way. \vspace{3mm}

% % --- Our goal is to to identify task-relevant text over distinct types of natural language software artifacts with high accuracy.  \vspace{3mm}

% % --- To this end, we explore a set of approaches (or their combination)
% % that exploit 
% % natural language processing techniques at 
% % the word and sentence level.  \vspace{3mm}


% --- When developing our approach, we use the \acs{DS-synthetic} dataset of manually curated task-relevant sentences produced in our characterization study~\cite{marques2020} \vspace{3mm}


\subsection{Word-level properties}

\rev{REVIEW}

% --- uses the novel \textit{Transformer}~\cite{Vaswani2017attention} neural network to jointly model the relevancy of a given input sentence with respect to a task. 

% --- Explain why we have selected the approach:

% ------ Our second approach investigates the applicability of pre-trained models that do not require large amounts of training data to our domain problem~\cite{devlin2018bert, Ye2016}. With this approach, we revisit findings on the trade-offs of using machine learning techniques to mine textual data~\cite{Chaparro2017, Bavota2016}.



\subsection{Sentence-level properties}

\rev{REVIEW}

% uses a set of properties in the text (including \textit{semantic frames}~\cite{fillmore1976frame}) to determine if a given sentence is relevant to the input task



% --- Explain why we have selected the approach:

% ------ With our first approach, we investigate whether a light-weight technique addresses the need of automatically identifying task-relevant text, what could potentially discourage the need for more complex and computationally expensive solutions~\cite{Bavota2016}


