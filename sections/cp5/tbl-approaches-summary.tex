
\begin{table}[H]
\centering    
\begin{scriptsize}
\begin{threeparttable}
\rowcolors{2}{}{lightgray}    
\begin{tabular}{ll}

% \hline

% \multicolumn{2}{c}{\textit{No lock screen controls ever}}  \\



\textbf{Identifier} &  \textbf{Description} \\

\hline


% \texttt{baseline} & 
% \parbox[l][1cm][c] {1.5cm}{lexical\\similarity} &
% \parbox[l][1cm][c] {8.5cm}{
%     Uses VSM to identify the top-n sentences most lexically similar to a task description as task-relevant
% }
% \\


\texttt{word2vec} & 
\parbox[l][1cm][c] {9.5cm}{
    Uses the Skip-gram model to identify the top-n sentences most semantically similar to a task description as task-relevant
}
\\

\texttt{BERT} & 
\parbox[l][.7cm][c] {9.5cm}{
    Fine-tunes BERT to predict the sentences that are relevant to an input task
}
\\



\texttt{meaningful} & 
\parbox[l][.7cm][c] {9.5cm}{
    Indicates that a sentence is relevant if it contains certain frame elements
}
\\



\texttt{related} & 
\parbox[l][.7cm][c] {9.5cm}{
    Indicates that a sentence is relevant if its frames match certain frames in a task title
}
\\





% \texttt{SEframes} & 
% \parbox[l][1cm][c] {1.5cm}{frame\\semantics} &
% \parbox[l][1cm][c] {8.5cm}{
%     Postprocessing filter used in conjunction with the other approaches to reduce false positives in an approach's output
% }
% \\

\hline


\end{tabular}
\end{threeparttable}
\end{scriptsize}
\caption{Summary of approaches used to automatically identify task-relevant text}
\label{tbl:approaches-summary}
\end{table}

