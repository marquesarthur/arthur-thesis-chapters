\section{Motivation}
\label{cp5:motivation}


When provided with a set of artifacts that potentially contain information relevant to their task,
software developers must inspect the artifact's content and locate the portion of the text that might be relevant to the task-at-hand. 
Some of the artifacts inspected are short enough that a developer can find if they contain any helpful information at a quick glance.
Some others are lengthy~\cite{Rastkar2013t} and factors such
as high time pressure or
the need to meet deadlines~\cite{meyer2019}
may lead a developer to quickly skim the document
in an attempt to find any of the text that is relevant to their task~\cite{Starke2009},
what Robillard and Chhetri summarize as the information \textit{filtering problem}:

\smallskip
\begin{bluequote}
    \textit{The burden  of having to sit through large amounts of irrelevant text, e.g., because of legacy information, boilerplate text, or because the text is intended for a reader other than the developer who is currently inspecting the artifact, to locate the pieces relevant to them}~\cite{Robillard2015}
\end{bluequote}



As \textit{unfruitful filtering} can 
cause a developer to abandon an artifact that could otherwise contain information  helpful to her task~\cite{Brandt2009a, Starke2009},
several studies have proposed automatic approaches to assist this activity. 
These approaches leverage textual cues as well as an artifact's meta-data and, ultimately, they have the goal of surfacing 
the most important information in a document, e.g., highlighting the text identified as relevant so that a developer can quickly 
locate it.


As examples of approaches, Xu et al.~\cite{Xu2017} and Ponzanelli et al.~\cite{Ponzanelli2015}
argue that words that appear in a task description and that also appear in sentences within an artifact serve as indicators of the sentence's relevance to the developer's task.
In turn, Silva et al.~\cite{silva2019} discuss that 
there is a lexical gap between a task description and the information associated 
with the solution for that task, which lead them to identify
relevant sentences based on word meanings.
In a similar vein, Di Sorbo et al. suggest that relevant information might be identifiable 
according to the text's purpose, such as if it details a feature request, a problem, a solution proposal and others~\cite{Sorbo2015}.


Although effective, the cues used to automatically identify text relevant to a software task in the aforementioned studies have focused on specific tasks (\red{example + ref}) and artifact types (\red{example + ref}).
Therefore, the question of whether these cues can identify relevant text across a wider range of artifact types and tasks remains open. 



As a first step towards answering this question, we set out to investigate:


\begin{enumerate}
    \item \textit{How accurately can lexical properties identify text deemed relevant to a task?}
    We assess to what extent can a lexical similarity approach automatically identify text relevant to a software task.
    We use lexical similarity as a baseline since both our card sorting analysis (\red{Section~\ref{aaa}}) and related work~\cite{Ko2006a, Freund2015} has shown
    that developers often use keyword-matching as a simple and quick search strategy to locate relevant information in a software artifact.


    \item \textit{How accurately can word semantics identify text deemed relevant to a task?}
    Guided by studies that discuss there are lexical gaps between a task description and the text related to that task's solution~\cite{silva2019, Huang2018, Ye2016},
    we ask if we can identify text relevant to a software task by semantically matching the text in a task and the text within an artifact.
    To answer this question, we explore how can we use language models~\cite{Devlin2018Bert, Mikolov2013} to identify  task-relevant text.

    
    \item \textit{Does the relevance of a sentence depend on the sentence's meaning?}
    Our study on characterizing task-relevant text (\red{Section~\ref{aaa}}) has show that text deemed relevant often contains semantic frames describing 
     required events, obligations, actions evoking system calls, etc.
    Given how these frames capture key factors used to understand a sentence's meaning
    and also their prominence in relevant text, 
    we assess if semantic frames help to filter task-relevant text.
\end{enumerate}




