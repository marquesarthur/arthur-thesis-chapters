\setcounter{chapter}{3}
\setcounter{rq}{1}


\chapter{Android Task Corpus}
\label{ch:identifying}



\vspace{1mm}

--- One of the challenges for characterizing task-relevant information as well as for proposing automatic techniques to automatically identify task-relevant text is 
the lack of corpora containing 
software tasks and associated artifacts originating from heterogeneous sources.


--- To fill this gap, this chapter contributes with the Andorid tasks corpus (\acs{DS-android}), a dataset with 300 tasks originating from StackOverflow questions comprising Andorid development
as well as from GitHub issues on a variety of Android Open-Source Systems. 



--- Creating a foundation, well-structured corpusis itself a contribution to scientific progress. It lays the foundation 
for several studies that explore relationships between software tasks and natural language artifacts. Therefore, this chapter describes our methodology for the creation of such a corpus.



\section{Software Tasks}
\textcolor{white}{force ident} % this is just for the chapter outline

--- We consider a software task as a piece of work undertaken by a developer that often has to be finished within a certain time~\cite{2004merriam}. 
Two common places a software task can be found are:

\begin{itemize}
    \item the description of a bug or feature request reported in a bug tracking systems; or in
    \item a post in a community forum, development mailing lists, and others.
\end{itemize}

\vspace{3mm}

--- Given this definition, we select tasks from StackOverflow and GitHub to build our corpus

------ We scope task selection to the \textit{Android} development domain such that we can select common tasks across the two sources \vspace{3mm}



--- Detail that StackOverflow tasks were selected from Baltes et al. dataset~\cite{baltes2019-rep}

------ Give example of a StackOverflow task \vspace{5mm}

--- Because there is no GitHub dataset promptly available, we selected GitHub issues from top starred Android projects on GitHub 

------ Projects were selected among Open Source Systems that had the \textit{Java} and \textit{Android} tags. 

------ We randomly sampled 15 issues from a total of 10 distinct projects

------ Describe how we avoid common pitfalls  when mining GitHub~\cite{kalliamvakou2014}

------ Give example of a GitHub task 

\section{Artifact Selection}
\label{cp4:corpus-artifacts}
\textcolor{white}{force ident} % this is just for the chapter outline


--- Our artifact selection approach seeks to simulate everyday practices on how developers search the Web~\cite{rao2020, Xia2017} \vspace{3mm}

--- To that end, we consider a task's title (i.e., SO question or GitHub issue title) as the seed used to search for pertinent artifacts in a search engine

------ This is a common procedure adopted by many studies in the field (e.g.,~\cite{Xu2017} or ~\cite{Silva2019}). \vspace{3mm}


--- As there are many different sources of artifacts, we restrict artifact selection to well known and studied sources~\cite{Starke2009,Kevic2014, Li2013}:


\begin{itemize}
    \item Android and Java SE API documentation;
    \item Github issues;
    \item StackOverflow answers; and
    \item Websites from the java and android categories on Alexa~\cite{alexa}.
\end{itemize}


\vspace{3mm}

--- For these sources, we use the \texttt{googlesearch} API~\cite{googlesearch} to perform Web searches

------ Results were limited to English and a maximum of 5 resources per source 

------ These limitations were necessary because of throttling or even blocking mechanisms in the APIs used the fetch data in each of the sources considered \vspace{3mm}

--- Provide descriptive statistics for the corpus

------ 300 tasks, 150 from SO and 150 from Git

------ Approximately 2,500 artifacts

------ Almost 260,000 sentences



% \acs{AnsBot} 

% \acs{Krec} 

% \acs{Hurried} 

% \acs{DS-synthetic} 

% 

% \acs{DS-android-small}

% \acs{DS-android-large}