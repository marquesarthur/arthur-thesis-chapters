\setcounter{chapter}{4}
\setcounter{rq}{1}


\chapter{Identifying Task-Relevant Text}
\label{ch:identifying}

The information a developer seeks to help aid the completion of a task typically exists
across a range of artifacts. 
To aid developers identify, from the large amount of text
in these documents, just the fraction of text relevant
to the task-at-hand, prior work has used syntactic properties of the text
---alongside an artifact's meta-data---
 to identify likely relevant text (\red{Chapter~\ref{}}).
Although effective, these techniques target specific
types of artifacts, limiting their use across the 
many different kinds of artifacts developers encounter
daily in their work.



In this chapter, we explore a design space of possible techniques building on approaches to interpret the meaning, or semantics, of text
to identify task-relevant text across different kinds of software artifacts.
We introduce six possible techniques that incorporate the  
semantics of words and sentences. 
We show that some of the proposed semantic-based techniques 
compare to existing artifact-specific techniques 
and that they apply to a broader set of artifacts.






%To answer this question, we explore a set of approaches from previous related work and of our own 
%for the automatic identification of text that might contain information relevant to a particular software task.
%Through usage of human-annotated data produced earlier in this thesis, we 
%investigate how accurately can these techniques identify text relevant to software development task.
We start by outlining the hypotheses that motivate the techniques that we explore (Section~\ref{cp5:motivation}) followed by detailed descriptions of the
techniques (Section~\ref{cp5:approaches}).
We show how the six techniques that we explore 
compare against state-of-the-art artifact-specific techniques 
(Section~\ref{cp5:comparison}) and 
their accuracy across different types of artifacts (Section~\ref{cp5:evaluation}). 
Section~\ref{cp5:summary} summarizes our key findings.

\clearpage




\input{sections/cp5/motivation}
\input{sections/cp5/background}
\input{sections/cp5/approach}
\input{sections/cp5/evaluation}
\input{sections/cp5/comparison}
\input{sections/cp5/summary}




% \setcounter{chapter}{4}
% \setcounter{rq}{1}


% \chapter{Identifying Task-Relevant Text}
% \label{ch:identifying}



% Designing an automatic technique able to identify text relevant to a task across the range of artifacts a developer might seek information on means solely using data common to these different artifacts.
% We have shown how  prior work uses syntactic properties (alongside an artifact's meta-data)
% to detect relevant text in specific artifact types.
% We have also shown that, in a small set of tasks and artifacts, task-relevant text might be identified through its semantics.
% A natural question that follows is whether we can use these properties to identify relevant text across a wide variety of software tasks and artifacts.




% To answer this question, we explore a set of approaches from previous related work and of our own 
% for the automatic identification of text that might contain information relevant to a particular software task.
% Through usage of human-annotated data produced earlier in this thesis, we 
% investigate how accurately can these techniques identify text relevant to a particular software development task.
% We start by outlining the hypotheses that motivate the techniques that we explore in Section~\ref{cp5:motivation}.
% We present details about the techniques themselves in Section~\ref{cp5:approaches}.
% Section~\ref{cp5:evaluation} describes evaluation results while
% Section~\ref{cp5:summary} summarizes our key findings.



% \input{sections/cp5/motivation}
% \input{sections/cp5/approach}
% \input{sections/cp5/evaluation}
% \input{sections/cp5/summary}

