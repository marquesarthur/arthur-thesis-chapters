

When performing software tasks in large and complex software systems, software developers typically consult a number of different kinds of artifacts that might assist task completion~\red{\cite{}}. For example, 
when developing an Android application, a developer might consult official Android API documents and guidelines~\red{\cite{}} or seek question-and-answer forums for functionality, security and performance-related information~\cite{parnin2012}.




Much critical information in this and other non-source code types of artifacts 
% that developers seek information on 
contain data in the form of unstructured text~\cite{Bavota2016} and 
a developer must read the text to find the information that is \textit{relevant} to their task.
However, the sheer amount of information \textit{within} these natural language artifacts may prevent a developer from comprehensively assessing what is needed to complete their task correctly and completely~\cite{Murphy2005}.  Just within one kind of document, API
documentation, studies have shown that it can take 15 minutes or more
of a developer's highly constrained time to identify 
information needed to perform a particular software task~\cite{endrikat2014, Meyer2017}.
Therefore, finding task-relevant information can be a time-consuming
and cognitively frustrating process~\cite{Begel2008,
robillard2011field}.




As tasks become more complex~\cite{Pirolli2007, Bystrom1995}, a developer might also need to forage
for more artifacts---locating and combining information to understand what is needed for the task-at-hand~\cite{Piorkowski2016}. If no tool support is provided, much of the process of discovering 
task-relevant information falls on the developer's shoulders~\red{\cite{}} and 
a developer that fails to locate all, or most, of the information needed
 will have an incomplete or incorrect basis from which to perform that task~\red{\cite{}}.





Recognizing the need to support a developer's discovery of information relevant to their task, 
researchers have developed a number of
\textit{artifact-centric} techniques
to extract
information that can be embedded in
tools for software developers. 
A number of the techniques commonly employed by researchers are based on the
frequency of co-occurrence of words, or phrases, in these software artifacts.
An early example is the use of lexical relations to index
software libraries~\cite{maarek1989}. Since this early use, software engineering
researchers have continued to leverage advances in
these approaches, applying Latent Semantic
Analysis (LSA)~\cite{deerwester1990LSI} to help cluster software components to aid
program comprehension tasks~\cite{Marcus2003}, or using 
word embeddings~\cite{Mikolov2013} to support the retrieval of API
examples in question-and-answer web sites~\cite{nguyen2017}.






Although effective in specific contexts, this support is
generally limited to identifying text within a specific kind of
artifact, such as API documentation~\cite{Robillard2015, Xu2017} or
code tutorials~\cite{Jiang2016b, Jiang2017}. 
Nonetheless, it is reasonable to assume
that the information extracted and presented by these and other 
techniques might not apply to all the artifacts types that a developer might seek 
information on~\cite{Liu2019, Brandt2009a}
and that individuals assessing the same artifact may have different
information needs that depends on the task that they perform~\cite{Bavota2016, Walters2014}.



\art{I need to connect the previous arguments to semantic techniques. Otherwise, it will appear in the thesis statement without the proper context?}



% These arguments that lexicon-based natural
% language techniques are not applicable is often based
% on a need for access to the \textit{meaning} of
% sentences in the natural language text~\cite{DiSorbo2015, gu2015, Arya2019}. Whenever similarity arises in the reasons for
% why existing approaches are insufficient,
% it raises the question
% of whether there exists an approach that might fill
% the gap.
