

When performing software tasks in large and complex software systems, software developers typically consult several different kinds of artifacts that assist them in their work~\cite{Starke2009, Meyer2017}. For example, 
when incorporating a new API library needed for a new feature, a developer might consult official API documents and guidelines~\cite{robillard2011field, umarji2008archetypal} or 
 question-and-answer forums for functionality, security and performance-related topics~\cite{parnin2012, silva2019}.



Much critical information in this and other non-source code types of artifacts 
contain data in the form of unstructured text~\cite{Bavota2016} and 
a developer must read the text to find the information that is \textit{relevant} to the task being performed.
However, the sheer amount of information \textit{within} these natural language artifacts may prevent a developer from comprehensively assessing what is useful to their task~\cite{Murphy2005}. Just within one kind of document, API
documentation, studies have shown that it can take 15 minutes or more
of a developer's highly constrained time to identify 
information needed to perform a particular software task~\cite{endrikat2014, Meyer2017}
and a developer that fails to locate all, or most, of the information needed
 will have an incomplete or incorrect basis from which to perform a software task~\cite{Murphy2005}.



 \section{Scenario}
 \label{cp1:example}
 
 
 
 
 To illustrate challenges in locating information useful for a task, let us consider an  Android mail client application\footnote{\url{https://github.com/k9mail/k-9}}.
 Figure~\ref{fig:android-notifications-task} shows a task---in the form of a GitHub issue\footnote{\url{https://github.com/k9mail/k-9/issues/1741}}---that indicates that the app notifications 
 are not working as expected in the Android 7.0 version. 
 
 \medskip
 \begin{figure}[h!]
     \centering
     \includegraphics[width=.85\textwidth]{cp1/android-quick-actions}
     \caption{k-9 mail GitHub issue \#1741 indicating that quick actions don't get displayed on Android 7.0}
     \label{fig:android-notifications-task}
 \end{figure}
 
 
 \medskip
 A developer assigned to this issue might not be familiar with how Android notifications work and thus, they will need additional knowledge to understand and resolve the bug~\cite{ko2007, Li2013, sillito2006}. 
 More than often, this knowledge can be acquired from a developer's peers~\cite{singer2011}. 
 However, the fragmented and distributed nature of software development  
 may prevent the developer from accessing their peers~\cite{ko2007},
 what often makes  them seek online web resources for information 
 that may assist them in completing the task-at-hand~\cite{Xia2017, rao2020}.
 
 
 
 
 
 \begin{figure}
     \centering
     \includegraphics[width=.75\textwidth]{cp1/search-results.pdf}
     \caption{Search results showing artifacts of potential interest to the Android quick actions issue}
     \label{fig:android-search-results}
 \end{figure}
 
 
 
 A common way to find software artifacts
 pertinent to the developer's task
 is through the usage of a web search engine~\cite{Brandt2009a, Li2013},
 what will eventually provide to the developer 
 a set of artifacts, such as the ones shown in 
 Figure~\ref{fig:android-search-results}, which the 
 developer will inspect in search for information 
 that will eventually explain how the Android notifications 
 work and why they are not being displayed properly. 
 
 
 
 
 However, finding information useful to the developer's task 
  in these and other 
 pertinent artifacts can be a time-consuming
 and cognitively frustrating process~\cite{Begel2008,
 robillard2011field}.
 First, an artifact such as the web tutorial retrieved in the developer's search 
 and detailed in Figure~\ref{fig:android-create-notification}
 might contain legacy information, boilerplate text, or sections 
 intended for a target audience other than the developer reading it (e.g., novice programmers)~\cite{Robillard2015}.
 This artifact contains nine distinct sections and a total of approximately 200 sentences.
 Reading all of its content would take approximately 10 minutes or more\footnote{Using a standard reading metric of 200 words per minute~\cite{Just1980}} of a developer's time~\cite{endrikat2014, Meyer2017} when only a portion of the text 
 might be relevant to the quick actions issue. For example, 
 Figure~\ref{fig:android-create-notification} shows
 that the Android notifications tutorial 
 has information about both the Android versions 7.0 and 12.0 and, given that the developer's task is related to the former version, only the text highlighted (in orange)
 might be of relevance.
 
 
 
 
 As tasks become more complex~\cite{Pirolli2007, Bystrom1995}, a developer also has to combine multiple textual fragments---from the same artifact or from different ones---to understand what is needed for the task-at-hand~\cite{Piorkowski2016}. 
 For example, the information within the web tutorial 
 might have only partially assisted the developer in understanding how 
 Android notifications work and thus, they would consult other artifacts from their search for more information, namely the API document and \acs{qa} web page. 
 Figure~\ref{fig:anatomy-of-relevant-text} gives further insight into 
 how task-relevant text 
 is scattered across these other artifacts. 
 From the figure, we find that some of the text potentially relevant to this task (in orange) is attached to elements that a reader would not intuitively access~\cite{Robillard2015}, i.e., 
 a sentence at the end of a paragraph or a comment under the original question,
 and if no tool support is provided, much of the process of finding this relevant text falls on the developer's shoulders~\cite{gonccalves2011, Ko2006a, Bystrom1995}.
 
 
 
 Researchers have long recognized the value of 
  assisting developers in locating information in the natural language artifacts sought as part of a software task,
 proposing many tools and approaches 
 that combine \acf{IR}, \acf{NLP} and \acf{ML} techniques to identify potentially useful text in certain kinds of artifacts. 
 For example, Nadi and Treude consider 
 that relevant information in \acs{qa} 
 web pages are often found in text with
 conditional clauses (i.e., sentences with the word `\textit{if}')~\cite{nadi2020}
 while Robillard and Chhetri assume that relevant 
 text in API documents mention a code element such as a class name or method signature~\cite{Robillard2015}; they use such assumptions 
 in techniques that identify this text automatically.
 As other examples, both Xu et al.~\cite{Xu2017} 
 and Silva et al.~\cite{silva2019} use 
 meta-data available on each of the answers in a Stack Overflow post 
 as a proxy for relevant information.
 That is, they use the number of votes an answer has or the checkmark indicating if an answer is the correct one, both shown in Figure~\ref{fig:anatomy-of-relevant-text}, 
 to automatically identify text that might be relevant to a given task in these answers. 
 
 
 
 % https://tex.stackexchange.com/questions/468393/including-large-images-in-landscape-formatting
 \begin{landscape}
 \begin{figure}
     \centering
     \includegraphics[width=\dimexpr\linewidth-4\fboxsep-2\fboxrule]{cp1/create-notification.png}
     \caption{Snapshot of the official Android notifications API overview}
     \label{fig:android-create-notification}
 \end{figure}
 \end{landscape}
     
 
 
 
 
 
 \begin{landscape}
 \begin{figure}
     \centering
     \includegraphics[width=\dimexpr\linewidth-4\fboxsep-2\fboxrule]{cp1/notifications-relevance-2.pdf}
     \caption{Relevant text for the Android notifications task found across different kinds of artifacts, i.e., an API document (on the left) and a question-and-answer web page (on the right)}
     \label{fig:anatomy-of-relevant-text}
 \end{figure}
 \end{landscape}
 
 
 
 
 Although effective in specific contexts,
 it is reasonable to assume that these techniques might not apply 
 to the different kinds of artifacts. This is either because these techniques have  assumptions on the nature of relevant text that do
 not extend to the text found in other types of artifacts, or 
 because these techniques rely on 
 meta-data, which is only available in specific kids of artifacts
 and given how quickly developers progress to using new kinds of technology to
 record pertinent information (e.g., slack~\cite{Storey2017, Lin2016}),
 it may be difficult to scale such artifact-centric approaches to cover the range of
 artifacts that 
 a developer may encounter
 daily in their work~\cite{Li2013}.
 
 
 This scenario illustrates thus some of the challenges in locating task-relevant textual
 information and motivating the need for more generalizable techniques.
 
 




% \clearpage


% a snapshot 
% of the Android notifications documentation, where among  
% the many topics presented on the page (right-hand side), only the `\textit{notification actions}' portion (under focus) might be rof relevance.
% This illustrates the burden of sifting through large amounts of
% irrelevant text (e.g., because of legacy information, boilerplate text, or because it is intended for another audience) to filter just those parts that are relevant to a developer~\cite{Robillard2015}. 











% about adding
% action to a notification is found across multiple artifacts.
% If no tool support is provided, much of the process of navigating through artifacts of interest and locating text 
% relevant to a task fall on the developer's shoulders~\cite{gonccalves2011, Ko2006a, Bystrom1995}.






% Researchers have long recognized the value of assisting developers in 
% identifying information of relevance within the natural language
% text of a software artifact






% but such a technique would fail to locate the relevant text 
% shown in Figure~\ref{fig:anatomy-of-relevant-text}.


% consider pre-defined kinds of tasks or types of artifacts.
% For example, {\small DeMIBuD}~\cite{Chaparro2017} is a technique that applies to bug reports and 
% assists in bug triaging. Although valuable, the text   detailing a bug's observed or expected
% behaviour and automatically identified by this tool
%  is of little help to a developer who accessed that bug 
% with the hope that the bug's solution also applies to their current task~\cite{Viviani2019}.





% \input{fig/cp1/search-results.tex}





% While it is impractical to anticipate all the information needs a developer might have~\cite{sillito2006, josyula2018, ko2007}, there is an increasing interest in using the information 
% available in a software task for the purposes of automatically identifying text 
% which might assist in completing that task~\cite{Bavota2016}. 
% In such context, most of the approaches proposed by software engineering researchers 
%  only apply to certain kinds of artifacts, such as Stack Overflow posts~\cite{Xu2017, silva2019}, 
%  and use structural data available in these artifacts (e.g., extracting text only from top ranked answers)  to assist in the identification of relevant text
 
% These assumptions limit using such techniques across the
% many different kinds of artifacts a developer may encounter
% daily in their work~\cite{Li2013}, 
% illustrating thus some of the challenges in locating task-relevant textual
% information and motivating the need for more generalizable techniques.





% \begin{landscape}
% \begin{figure}
%   \centering
%   \begin{minipage}{.5\textwidth}
%       \centering
%       \includegraphics[width=0.5\linewidth, height=0.2\textheight]{cp1/notification-anatomy}
%     %   \caption{The Skip-gram model architecture~\cite{Mikolov2013}}
%     %   \label{fig:skip-gram}
%   \end{minipage}%
%   \begin{minipage}{0.5\textwidth}
%       \centering
%       \includegraphics[width=\linewidth, height=0.2\textheight]{cp1/expand-notifications}
%     %   \caption{Positive and negative training examples~\cite{Ye2016}}
%     %   \label{fig:skip-gram-example}
%   \end{minipage}
% \end{figure}
% \end{landscape}





% Some \acs{NLP} techniques rely on regular expressions describing a sequence of tokens
% representing words or linguistic elements 
% often found in relevant text~\cite{Bavota2016, Chaparro2017}.
% Other \acs{ML}-based techniques use extractive text summarization 
% to produce a summary of an artifact's content~\cite{Lotufo2012, Ponzanelli2015}
% and a developer might use this summary to find key information
% that may help them complete their task~\cite{Bavota2016}.