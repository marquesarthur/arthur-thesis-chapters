

\subsection{Empirical Assessment}



Having designed techniques able to automatically identify text---in different artifact types---perceived by humans
as relevant to a variety of software tasks, we return to our thesis statement
and examine the impact of tools that use semantic-based techniques to assist developers in performing programming 
tasks. 



We present a controlled experiment where we asked participants with software development background to 
perform two programming tasks, where participants were assisted by a tool
that embeds one of the semantic-based techniques we have explored in one of these tasks.
Results from this experiment allow us to compare the correctness of solutions of each task 
performed by participants with and without tool assistance. 
We also compare the text that participants in our experiment manually indicated as relevant to the text automatically identified by our tool, discussing the usefulness of the tool-identified text according to the feedback provided by the participants. In summary, this experiment examines different aspects related to 
the usage of a tool for identifying text relevant to a developer's task.



\subsubsection{Approach}



\subsubsection{Evaluation}



\subsubsection{Novelty}