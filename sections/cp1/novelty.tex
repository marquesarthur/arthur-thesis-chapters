\section{State of the art}
\label{cp1:novelty}

% \gcm{We need to talk about these section.
% It still isn't sufficiently convincing to
% show the novelty of this thesis.}


To assist developers in discovering task-relevant information,
software engineering researchers have proposed 
a number of techniques or tools 
to automate the identification of  text.
Although effective in specific contexts, this support is generally constrained 
to certain
types of artifacts and support the multitude of artifact types that is constantly evolving
is challenging, if not impractical.



Artifact-specific approaches often use assumptions on the type of content 
and the meta-data available in an artifact
to automate the identification of relevant text.
Gaining insight into how developers produce and consume 
such artifacts to design artifact-specific techniques
 requires significant effort from the research community,
 where several empirical studies have investigated 
natural language artifacts 
and techniques using \acf{IR}, \acf{NLP}, or \acf{ML}  to automatically identify
relevant text~\cite{panichella2012, Ko2006, Arya2019, Maalej2013}.


However, designing and evaluating such approaches
does not follow the same pace with which developers start using
a kind of software artifact~\cite{garousi2019}.
By the time an artifact-specific tool might be available~\cite{gibbs1994},
it is possible 
that developers have progressed to using new kinds of technology,
as observed in the recent shift from 
development mailing lists to instant communication platforms such as Slack~\cite{Lin2016}. 



% \art{need a better connecting argument to this sentence}

Other approaches target long-lasting types of artifacts (e.g., API documents or bug reports). 
Nonetheless, due to the number of tools that aid developers in locating text relevant to different activities associated with these artifacts (e.g., bug triaging or requirements traceability),
it might be difficult for a developer to familiarize themselves 
with all of the existing tools
and to decide which tool to use in a given situation. \art{REV}




These barriers might be lifted by a tool that could serve as a single point of entry to the automatic identification of relevant text regardless of the kind of artifact a developer consults.
Such a tool could integrate the many existing tools (or their underlying techniques) and decide which one 
to use in which context. Nonetheless, 
due to an ever-growing the number of technologies used to record information,
anticipating the kinds of artifacts a developer might consult 
as part of a task is equally difficult.
Moreover, 
deploying the right technique for an artifact type
is challenging because developers 
assessing that artifact may have different
information needs than anticipated by these techniques~\cite{saracevic1975}.
\art{REV}




% For example, there are tools~\cite{Robillard2015, fucci2019} that aid developers in finding 
% information in API documents, but such tools would be of little to no help 
% if a developer decided to search 
% in an approach that uses a bug report's meta-data~\cite{Lotufo2012,li2018deep}, a 
% unified tool would have to 
% consider how to extract such data from different products 
% such as 
% GitHub Issues\footnote{\href{https://docs.github.com/en/issues/tracking-your-work-with-issues/about-issues}{Microsoft GitHub}} 
% or Jira\footnote{\href{https://www.atlassian.com/software/jira}{Atlassian Jira}}.
% As another example, different programming languages
% might have very different documentation styles~\cite{endrikat2014} and a 
% unified tool would have to either integrate approaches tailored to each style  
% or ensure that an approach for this kind of artifact
% consistently 
% extract text from the myriad of styles under use~\cite{robillard2011field}.



A second approach for general techniques could consider ways to relate the text in a task 
to the text in a natural language artifact and  
state-of-the-art tools (e.g.,~\cite{Xu2017, silva2019}) attempt to accomplish this using semantic techniques.
These tools have similar constraints due to also using an artifact's meta-data and other limitations arise from how they make use of semantics,
i.e., they default to a specific semantic approach~\cite{Ye2016} and do not investigate the range of semantic techniques~\cite{Mikolov2013, Devlin2018Bert, fillmore1976frame} 
that might apply to text in software engineering artifacts.






These limitations suggest the need for a more generalizable technique
that can evolve to 
identify relevant text in potential new kinds of artifacts 
and that is easier to deploy/install than many.
If one technique could identify relevant text across all kinds
of artifacts a developer encounters, the technique
could apply in all situations and may be more adoptable in industry
as a result. 




% it may be difficult to apply such artifact-centric approaches to cover the range of artifacts sought by a developer



% For example there have been approaches that automatically identify text 
% in API documentation~\cite{Robillard2015, fucci2019}, development mailing lists~\cite{panichella2012, Sorbo2015}, bug reports~\cite{Lotufo2012, li2018deep}, 
% question-and-answer developer forums~\cite{nadi2020, Xu2017, silva2019}, and others. 




% ,
% and 



% In API documentation, Robillard and Chhetri investigated how to automatically identify 
% sentences key to using an API element~\cite{Robillard2015}.
% Their approach uses regular expressions to match the text in this kind of artifact 
% to a set of patterns derived from the Java SDK 6 documentation.
% More complex approaches, i.e.,  \acf{ML} and \acf{DL},
% were also used by Fucci et al.
% with the purpose of automatically identifying sentences with 
% directives, concepts, examples, and other types of information included in API documents~\cite{fucci2019}.



% In development mailing lists, Panichella et al. 
% proposed an automatic approach leveraging \acf{IR} to extract 
% text with useful information that assists in understanding code elements inspected by a developer~\cite{panichella2012}
% while Di Sorbo et al. use linguistic patterns---extracted via \acf{NLP}---to
% automatically categorize the content of development emails, what might 
% assist developers in finding text specific to some category, e.g., 
% finding text about the solution for a bug or text discussing potential 
% new features for a system~\cite{Sorbo2015}.



% In bug reports, researchers have mostly applied text summarization
% as a means of identifying text that a developer would first read when inspecting a bug report, 
% which might assist developers in finding useful information for their task;
% and both \acs{ML} and 
% \acs{DL} techniques have been investigated for this purpose, 
% e.g.,~\cite{Lotufo2012} or~\cite{li2018deep}.



% In community forums and \acs{qa} pages, researchers have explored both lexical 
% and syntactic approaches for the automatic identification of sentences that would 
% help a developer quickly decide if the content in these artifacts is relevant to 
% a developer's task~\cite{nadi2020}. Other approaches have also considered extracting information relevant to a developer's 
% programming task combining query-based summarization 
% and meta-data available on Stack Overflow~\cite{nadi2020, Xu2017, silva2019}.





% To understand the state of the art
% in assisting developers in locating relevant information in the natural language artifacts, 
% we survey some of the artifacts studied and 
% the approaches proposed to
% automate the extraction of text from these artifacts.
% Although we do not claim that the list of artifacts and techniques presented hereafter is complete,
% they comprise common artifact types sought by developers~\cite{umarji2008archetypal, Li2013}
% and many of the techniques used to parse the natural language text in them~\cite{arnaoudova2015}.






% researchers have developed a number of
% techniques
% to address the identification of which text is pertinent within an
% artifact.  However, this support is
% generally targets specific kinds of
% artifacts limiting the use across the
% many different kinds of artifacts developers encounter
% daily in their work. 
% ; 
% and integrating such artifact-specific approaches to allow users to seamlessly search
% for information is costly, if not impractical.



% This section
% elaborates these and other limitations in the state of the art.

% limiting the scope with which we can apply such techniques.
    

% use across the
% many different kinds of artifacts developers encounter
% daily in their work

% Many of the approaches that identify relevant text in a natural language artifact consider a single type of artifact. 
% For example, approaches that identify text in development emails~\cite{Sorbo2015} often use 
% data about the conversational aspects~\cite{Murray2008} in an email thread for this purpose.  




% For instance, a developer would have to understand the different kinds of information 
% extracted by 
% bug report summarization tools (e.g.,~\cite{Rastkar2010, Lotufo2012,li2018deep})
% or bug report text identification tools (e.g.,~\cite{huang2018automating, Arya2019, Chaparro2017})
% to decide which tool to use in a given situation. 
% (e.g., sentences about feature requests or that discuss the bug's status~\cite{huang2018automating, Arya2019}),
