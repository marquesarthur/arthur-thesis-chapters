

\section{Thesis}
\label{cp1:thesis}


% Developers produce such natural language artifacts on a 
% continuous basis~\cite{Rastkar2013t} 
% and locating the documents of interest for a task
% is not trivial~\cite{Starke2009}. 
% To better understand this activity, 
% many software engineering researchers 
% have studied  a developer's information foraging process~\cite{Pirolli1999}
% providing theories on how a developer searches for pertinent information
% and proposing tools to help this activity.

\gcm{It would be helpful to build to the thesis statement some. Something like ... The scenario we presented indicated that many kinds of artifacts that can be consulted
to help with a task and the challenges that a developer can face. In surveying the
state of the art, we demonstrated that existing techniques are tied to particular
artifacts. This thesis aims to overcome these limitations.}

Our thesis statement is that:


% As there is an underlying structure to many software development tasks~\cite{Murphy2005},
% we hypothesize that one can use information about a task to assist in 
% the design of \textit{artifact-agnostic} techniques able to  
% automatically identify text relevant to a developer's task~\cite{Starke2009, Bavota2016}. We posit that:


\bigskip
\begin{bluequote}
    \textit{A developer can effectively complete a software development task when automatically provided with text relevant to their task extracted from pertinent natural language artifacts
    by a generalizable technique.}
\end{bluequote}
\medskip



Designing a generalizable technique means 
\gcm{Does it really mean this or is this one way to develop a generalizable technique?}
determining if there are similar rules governing how text relevant to a task is 
constructed across different types of artifacts~\cite{Kintsch1978a}.
Hence, in the first part of this thesis, 
\gcm{first part?}
we ask what are common properties, if any, in the text deemed relevant 
to a software task and found across different types of artifacts?
To answer this question, we present a formative study that 
examines the text that twenty developers deemed relevant in artifacts 
of different types associated with six software tasks.

% 

By \textit{characterizing} task-relevant text found in different kinds of artifacts,
this study complements and adds to previous research that has
examined text relevant to particular tasks and one kind of artifact~\cite{Ko2006, Rastkar2010, Chaparro2017, Robillard2015}.
Notably, our analysis of natural language text  in bug
reports, API documents and \ac{qa} websites 
inspected as part of this study 
 show consistency in the meaning, or \textit{semantics}, of the
 text deemed relevant to a task by a developer, suggesting that 
semantics might assist in the automatic identification of
task-relevant text and in the design of a more generalizable technique.
% ~\cite{Meyer2019, Li2013}




Approaches that interpret the meaning of the text have been successfully used for a variety of development activities,
such as for finding who should fix a bug~\cite{yang2016}, searching for comprehensive code examples~\cite{silva2019}, or assessing the quality of information available in bug reports~\cite{chaparro2019}.
Nonetheless, we are not aware of their usage in techniques 
that assists developers in discovering task-relevant text over different types of natural language artifacts.
Hence, the second part of this thesis describes 
\gcm{second part?}
the investigation of a design space
of six possible techniques that incorporate the semantics of words~\cite{Mikolov2013, Devlin2018Bert}
and sentences~\cite{fillmore1976frame, marques2021}
to automatically identify text likely relevant to a developer's task.
Assessment of these techniques reveals that semantic-based techniques
achieve recall comparable to a state-of-the-art technique aimed at one type of artifact~\cite{Xu2017}, but 
that they do so across
multiple artifact types.








Provided that we find consistency in the text  that is relevant to a task within different kinds of artifacts and that semantic-based techniques can automatically identify such text, in the last part of this thesis, 
we consider whether these approaches can \textit{assist} a software developer while they work on a task.
We introduce \acs{tool}\footnote{
    Automatic \underline{Ta}sk-\underline{R}elevant \underline{T}ext \underline{I}dentifier
    \art{Tentative name :)}
}, a web browser plug-in that 
automatically identifies and highlights text relevant to a developer's task 
and then, we present a controlled experiment that investigates benefits brought by using this tool, if any.
We report how  participants 
performed two Python programming tasks when 
% provided with a
%  curated set of artifacts associated with the tasks considered
%  and 
 assisted (or not) by \acs{tool},
% to automatically identify task-relevant text  
% With this experiment, we compare the correctness of the solutions of each task 
% performed by participants with and without tool assistance
% and we also detail
% the perceived usefulness of the text automatically identified and shown by the tool. 
where experimental results indicate that participants found the text automatically identified
by the tool 
useful in two out of the three tasks of the experiment.
Furthermore, tool support also led to more correct solutions 
in one of the tasks in the experiment. Therefore, these results provide
initial evidence on the role of semantic-based tools 
for supporting a developer's discovery of task-relevant information
across different natural language artifacts.



% \art{should I have a concluding phrase here?}



% This experiment strengthen software engineering research on the 
% role of semantic-based tools for supporting
% automatic text identification~\cite{nadi2020, Xu2017,Lotufo2012}
% and we conclude this thesis by discussing implications of our findings and 
% directions for future work.




% To design such a generalizable technique, we ask what are common properties, if any, in the text deemed relevant to a software task and found across different types of artifact?



% that \textit{characterizes} task-relevant text 
% found in different kinds of artifacts. 



% To investigate this statement and to design a more generalizable technique, we ask what are common properties, if any, in the text deemed relevant to a software task? This question has been the focus of many software engineering studies~\cite{Piorkowski2015, Piorkowski2016, chi2007, Ko2006a} that have explained qualitative aspects that 
% guide a developer's decision on the relevance of natural language text~\cite{Forward2002, BenCharrada2016, Starke2009, DeGraaf2014}.
% % Many other studies have proposed tools that automatically identify text 
% % relevant to certain types of tasks and kinds of artifacts~\cite{Chaparro2017, Robillard2015, Xu2017}. 
% Researchers have also contributed with valuable corpora
% containing text annotated as relevant to particular tasks and artifacts~\cite{nadi2019Rep, Rastkar2010}
% as well as automatic approaches for extracting such text~\cite{Chaparro2017, Robillard2015, Xu2017}, 
% but investigating if  the properties 
% of the text in certain artifacts apply to different kinds of artifacts
% is beyond their scope~\cite{hutchinson2021, bird2009}.






% by

% few studies~\cite{Ponzanelli2017, Liu2018Unakite} have investigated if and how accurately such approaches identify
% text likely 
% useful to a developer's task across the different types of natural language artifacts available online.







% To determine whether
% techniques that build upon semantic approaches 
% apply to our domain problem,


% without the need for artifact-specific data,
% and that some of our techniques also perform equivalently well across
% multiple artifact types, what strengthens the claim that semantic-based  
% techniques are more generalizable.


% Assessment of these techniques considers the text that each of them identifies
%  over different types of artifacts
% associated with fifty Android development tasks 
% for which human annotators identified task-relevant text.