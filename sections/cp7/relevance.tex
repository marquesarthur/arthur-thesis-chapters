



%\section{Limitations \& Trade-offs}
\section{Relevance}
\label{cp7:relevance}

A primary assumption in this dissertation
is that there will be text in documents
associated with a software development
task that is commonly seen as \textit{relevant}
to the task. Chapter~\ref{ch:characterizing} demonstrates
that sufficient commonality of relevant
text does exist to support the development
of techniques and Chapter~\ref{ch:assisting} shows
that the automatically identified text
is seen as relevant. For instance,
some participants in the \acs{tool}
experiment indicated:

\smallskip
\begin{quote}
    ``\textit{The highlights were super useful, without them I would definitely had not been able to rapidly do the task.}''
\end{quote}


\begin{quote}
``\textit{With the highlighted references, I was able to move much quicker. I quickly glanced at each resource, reading just the highlights to determine how valuable that resource was. The highlights allowed me to focus on the most relevant resources, gathering the necessary information to complete the task. 
}''
\end{quote}

Yet, others who participated in the \acs{tool}
experiment disagreed with the concept that text
in these documents was important at all:





\smallskip
\begin{quote}
``\textit{I realized going through [the experiment] that I read very little free-form text when looking for solutions. Mainly code samples with clear, succinct examples or type/method definitions.}''
\end{quote}

\begin{quote}
``\textit{I'm not going to bother reading the text if I don't have to, especially when the code snippets are easy to understand.}''
\end{quote}




\smallskip
This feedback suggests that the kind of information considered useful in a document not only differs based on 
a developer's  \textit{explicit} versus \textit{implicit} reasoning, but also that it varies with the developer. 
It suggests that techniques will need to
be even more general to work across document
types: techniques will also need to work across
the different kinds of information in a document.
Future studies should more deeply investigate
the kinds of information developers deem as
relevant and explore how developers gauge relevance.





How and what developers consider relevant in
documents may also impact how techniques trade-off
precision versus recall. 
In Chapter~\ref{ch:identifying}, we indicated
the techniques we explored favored locating
all relevant text within an
artifact, in other words recall, rather
than focusing on 
correctly determining relevant text, in other
words precision. 
We made this decision because, as described in 
 (Chapter~\ref{ch:introduction}),
missing relevant text would mean that a developer might have an incomplete or partial view of the information needed, which may lead to
sub-optimal decisions.






However, when favoring recall,  we may obtain more false positives; non\-/relevant text indicated as relevant.
Due to the limited time developers spend inspecting a natural language artifact~\cite{Starke2009}, there is a chance that
 a developer could discard reading an artifact due to a false positive. 
 Although abandoning reading an artifact and moving to another artifact could lead to non\-/efficient work
 (i.e., a developer might have to perform further searches and perhaps revisit artifacts that they have already inspected),
we believe that the benefits of automatically identifying relevant text outweigh these risks. 
That is, inspecting an artifact without tool support is more time\-/consuming
than inspecting each sentence retrieved to judge their relevance to the task at hand. 
Future studies could explore the ramifications
of this trade\-/off in detail.







%This feedback suggests that we could have observed different usage behaviours if participants had the chance to decide when to invoke \acs{tool}.
%However, 
%our experimental design focused on comparing tasks using or not \acs{tool} and thus, participants did not have the option to 
%request \acs{tool} to automatically identify task-relevant text on the fly. 


%To understand who would use  \acs{tool} in which types of tasks or 
%what factors  influence the tool's usage,
%we would have to consider a different experiment with challenges and risks of its own.
%For example, designing a longitutional study investigating how developers 
%with different expertise and background
%of some open source community would use \acs{tool}.



% This feedback also brings to light one core limitation of our techniques:
% automatically identifying text relevant to a task is of little to no help
% to developers who focus on code snippets or to developers who disregard 
% reading the text in a natural language artifact.




%\paragraph{\textbf{Precision vs Recall.}}