\setcounter{chapter}{5}
\setcounter{rq}{1}


\chapter{Evaluating Text Automatically Identified}
\label{ch:assisting}




In a previous chapter, we have compared different semantic-based techniques for automatically identifying text relevant to a software task.
Such a comparison assisted us in determining the most promising approach, but it did not address whether 
the text automatically identified  
by these techniques can assist a software developer while working on a task.



To fill this gap, this chapter presents a controlled experiment that 
investigates how a tool that embeds one of such semantic-based techniques 
might impact how a developer works on a task. 
The experiment 
compares the solutions of developers who attempted three Python programming tasks with and without tool support
and it also reports several aspects associated with the text automatically identified by the tool,
e.g., how useful was the text automatically found and how does it compare to text that humans deem relevant
in the artifacts available in each task.





We start by outlining our experimental design (Section~\ref{cp6:method}) and then 
by detailing experimental procedures (Sections~\ref{cp6:procedures}).
We report results from the experiment (Section~\ref{cp6:results})
as well as threats to the validity (Section~\ref{cp6:threats}).
We conclude this chapter summarizing our key findings (Section~\ref{cp6:summary}).


\clearpage







% We conclude this chapter presenting threats to the validity of our experiment (Section~\ref{cp6:threats}) and 
%  summarizing our key findings (Section~\ref{cp6:summary}).




\input{sections/cp6/method}
\input{sections/cp6/procedures}
\input{sections/cp6/results}
\input{sections/cp6/threats}
\input{sections/cp6/summary}




% \art{I'm trying to set results in a manner similar to how we did in the ICPC paper---present an overview of what we evaluate in the section, describe the method of evaluation and then, the results.}


% \input{sections/cp6/summary}

