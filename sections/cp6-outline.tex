\setcounter{chapter}{5}


\chapter{Evaluating an Automated Approach to Task-Relevant Text Identification}
\label{ch:assisting}

% \gcm{It would be better if the title was more aligned
% with the earlier chapters. Maybe something like "Evaluating an Automated Approach to Task-Relevant Text Identification"}

In the last chapter, we showed that semantic-based approaches can help identify text in artifacts relevant to a task. 
In this chapter, we consider whether these approaches can assist a software developer while they \textit{work} on a task.



To investigate how semantic-based approaches might assist developers performing a task, we have designed a tool, in the form of a web browser plug-in, that automatically highlights 
text relevant to a particular software task.
This plug-in takes a developer's task and a software artifact as inputs and then, it applies its underlying semantic-based technique---\textit{BERT with no filters}---to identify sentences that likely contain information useful to the input task.

We investigate benefits brought by using this tool, if any, through a controlled experiment
where 24 participants completed three Python programming tasks using (or not) this tool. 
With this experiment, we show that participants considered the majority of the text automatically identified in the artifacts 
they perused useful and that 
our tool assisted them in producing a more correct solution for one of the experimental tasks.



We start by outlining the evaluation approach  (Section~\ref{cp6:method}). We then
detail experimental procedures  (Sections~\ref{cp6:experiment}) before reporting
results from the experiment 
(Section~\ref{cp6:results}).
Section~\ref{cp6:summary} concludes the chapter.

% ---\textit{BERT with no filters}---

% \clearpage



% \footnote{
%     
% }





% We conclude this chapter presenting threats to the validity of our experiment (Section~\ref{cp6:threats}) and 
%  summarizing our key findings (Section~\ref{cp6:summary}).




\input{sections/cp6/motivation}
\input{sections/cp6/experiment}
\input{sections/cp6/results}
\input{sections/cp6/summary}

% \gcm{Sorry if I missed it but do you outline the number of artifacts and type of artifacts per task?}
% \art{sorry. I will add that to the Artifacts session}



% \art{I'm trying to set results in a manner similar to how we did in the  (``Task-Relevant Knowledge Identification'')ICPC paper---present an overview of what we evaluate in the section, describe the method of evaluation and then, the results.}


% \input{sections/cp6/summary}

%  (``Task-Relevant Knowledge Identification'')