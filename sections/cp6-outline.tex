\setcounter{chapter}{5}
\setcounter{rq}{1}


\chapter{Evaluating Text Automatically Identified}
\label{ch:assisting}



In a previous chapter, we have shown that semantic-based techniques can identify automatically parts of  text 
that human annotators deemed relevant in a number of artifacts associated with Android tasks. In this chapter,
I  address whether  text automatically identified using these
techniques can assist a software developer while working on a task.

This chapter presents a \textit{controlled experiment}
where I evaluate how a tool that embeds one of such semantic-based techniques impacts the completion of a software task.
We use three software tasks related to well-known Python modules and
we report qualitative and quantitative results from \red{15} participants with software development background who attempted these tasks. 
\gm{A bit more description of
the setup might be needed.}
We publicly share experimental materials and results to help future research in the field~\cite{experiment_material}.


We describe experimental procedures (Section~\ref{cp6:procedures}) before
presenting the results of our experiment (Section~\ref{cp6:results}). Section~\ref{cp6:summary} summarizes our key findings.





\input{sections/cp6/procedures}
\input{sections/cp6/results}
\input{sections/cp6/summary}




% complete software tasks when assisted, or not, by a tool that 
% embeds one of our semantic-based techniques. 
% \gm{'evaluate how' is a bit unspecified
% as 'how' isn't usually evaluated -
% maybe restate as 'investigate how tools that ... impact how ...'?}