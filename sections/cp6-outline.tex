\setcounter{chapter}{5}


\chapter{Evaluating an Automated Approach to Task-Relevant Text Identification}
\label{ch:assisting}

% \gcm{It would be better if the title was more aligned
% with the earlier chapters. Maybe something like "Evaluating an Automated Approach to Task-Relevant Text Identification"}

In the last chapter, we showed that semantic-based approaches can help identify text in artifacts relevant to a task. 
In this chapter, we consider whether these approaches can assist a software developer while they \textit{work} on a task.


We introduce a tool, in the form of a web browser plug-in, that automatically highlights 
text that it determines as relevant to a particular software task.
This tool embeds one of our semantic-based approaches---\textit{BERT with no filters}---and we investigate
how 24 participants complete three Python
programming tasks when assisted (or not) by such a tool through a controlled experiment\footnote{
    The \acs{UBC} \acs{ERB} approved the research conducted in this chapter under the certificate \textit{H19-04054}.
    A replication package is also publicly available~\cite{cp6_supplementary_material}.
}. 
With this experiment, we show that participants considered the majority of the text automatically identified in artifacts 
of each task useful and that 
our tool assisted them producing a more correct solution for one of the experimental tasks.


We start by outlining the evaluation approach  (Section~\ref{cp6:method}). We then
detail experimental procedures  (Sections~\ref{cp6:experiment}) before reporting
results from the experiment 
(Section~\ref{cp6:results}).
Section~\ref{cp6:summary} concludes the chapter.

% ---\textit{BERT with no filters}---

% \clearpage









% We conclude this chapter presenting threats to the validity of our experiment (Section~\ref{cp6:threats}) and 
%  summarizing our key findings (Section~\ref{cp6:summary}).




\input{sections/cp6/motivation}
\input{sections/cp6/experiment}
\input{sections/cp6/results}
\input{sections/cp6/summary}

% \gcm{Sorry if I missed it but do you outline the number of artifacts and type of artifacts per task?}
% \art{sorry. I will add that to the Artifacts session}



% \art{I'm trying to set results in a manner similar to how we did in the  (``Task-Relevant Knowledge Identification'')ICPC paper---present an overview of what we evaluate in the section, describe the method of evaluation and then, the results.}


% \input{sections/cp6/summary}

%  (``Task-Relevant Knowledge Identification'')