\section{Information Foraging and Relevance Theory}
\label{cp2:foraging}



Information foraging~\cite{Pirolli1999}
and relevance theory~\cite{clark2013relevance, saracevic1975, Saracevic2007c, Saracevic2007b} 
provide the theoretical background of this thesis.


Information foraging explains how 
an individual navigates through some search space looking for \textit{information patches} based on 
a set of cues about the effort and gains that a patch provides to them~\cite{Pirolli1999}.
In such context, foraging occurs \textit{between} or \textit{within} patches, i.e., 
searching which documents are relevant and what within a document is of relevance.
As a forager must constantly judge
the relevance of a patch, \textit{relevance theory}~\cite{clark2013relevance, saracevic1975} further elaborates the relationships between an information object (i.e., text in an artifact),
some context (i.e., a task), and what properties guide the relevance assessment (i.e., utility, completeness, etc.)~\cite{Saracevic2007c}.



Software engineering researchers (e.g.,~\cite{Piorkowski2015, Piorkowski2016, chi2007, Xia2017}) have extensively borrowed from information foraging and relevance theory
to understand how software developers find  information pertinent to their software tasks.
As one example,
Barry suggests factors that individual use when deciding whether to inspect (or not) a document in the search space~\cite{Barry1994}
while Forward and Lethbridge describe criteria regarding the 
content of an artifact, the presence of examples, and the document's structure as
 common attributes that developers use to assess the relevance of software engineering documentation~\cite{Forward2002}.
% Other studies have also found that 



In the context of programming tasks, Starke et al. explain that software developers form a set of hypotheses about their software task,
translating these hypotheses into to multiple search queries that will lead them to artifacts likely relevant to a task~\cite{Starke2009}. 
They observe that instead of systematically inspecting search results,
developers often skim through the results to decide which documents are relevant to a task. 
These findings were also observed by Brandt et al. when studying how
developers interleave web foraging, learning and writing code 
to accomplish software tasks~\cite{Brandt2009a}.


This thesis adds to the existing theory by discussing 
textual cues in the text that several software developers deemed relevant 
to complete software tasks.  

% emphasizing that web resources are used both for learning and for reminding. 





% While existing studies shed light upon many aspects regarding relevance,
% one premise
% in many software engineering approaches is the existence of corpora containing information
% annotated as relevant~\cite{Jiang2016b, Robillard2015}.  
% To create a
% corpus, annotators often follow a coding guideline and reconcile disagreements.  However, there are many criteria in how individuals
% assess relevance~\cite{Barry1994, Barry1998, Freund2015} and they may
% or may not reach consensus~\cite{Saracevic2007c}.
% By investigating how several software developers assess textual cues in the content of a patch to determine its relevance (Section~\ref{sec:rq-initial-study}),
% we aim to add to the existing theory of assessing relevance within a patch.



% \subsection{Artifacts}



% Software development often requires knowledge beyond what developers already posses~\cite{Li2013}
% and thus, software developers use different information sources to fill such gaps. 
% More than often, a developer will ask if any of their peers has the information that they need~\cite{singer2011}. 
% However, the fragmented and distributed nature of software development work 
% might prevent a developer from acquiring information from their peers~\cite{ko2007}.
% Due to this and other reasons, a developer might seek
% online web resources for information 
% that may assist them to complete the task-at-hand.




% As a first step in the forage process, a developer must
% find artifacts of interest for a task. 
% Typically, a developer starts with an information need,
% which they then translate into a query---manual or tool-assisted---that will 
% produce a list of artifacts that might address their information need. 


% To help this activity,
% several approaches have been developed (e.g.,
% Hipikat~\cite{Cubranic2005}, Libra~\cite{Ponzanelli2017},
% BIKER~\cite{Jiang2017}).  
% Hipikat relies on the concept of a
% group memory to recommend artifacts to a developer based on the current task.
% The group memory is formed by mining and relating artifacts
% associated with the software development~\cite{Cubranic2005}.
% Libra 
% keeps track of which artifacts are visited and recommends
% new artifacts to consider according to their prominence or complementarity to the
% visited ones~\cite{Ponzanelli2017}.  Finally, BIKER assists developers
% in selecting appropriate APIs for their tasks by using StackOverflow
% to capture how an API is often used~\cite{Jiang2017}.



% looking for artifacts that she judges pertinent to her task.
% To help developers address the initial problem of finding pertinent artifacts, 
% developed approaches use standard Information Retrieval (IR) techniques or more advanced ML techniques. 


