



\section{Textual Analysis in Natural Language Software Artifacts}
\label{cp2:text-in-se}



In this section, we detail empirical studies investigating 
textual data in natural language software artifacts. 
Such textual data is  rich in semantic information~\cite{dekhtyar2004} 
and we provide and overview of seminal work 
investigating lexical, syntactic, and semantic aspects of the text.




Initial insights about the text of a natural language artifact might be learned focusing on 
the characters or tokens in the text.
This lexical analysis~\cite{jurafsky2014speech} might be used to identify common or unique words 
used in a set of artifacts as well as to identify words that often appear together in the text.
In software engineering research, Bacchelli et al. used lexical analysis to study how developers describe class elements
in nearly 80,000 emails of an Open Source System~\cite{bacchelli2009}.
Their analysis suggests that lexical terms could be 
used as a mean of automatically linking information in development emails to 
the project's source code.







Syntactic analysis concerns the  elements in the text 
and the grammatical relationships between them~\cite{jurafsky2014speech}. 
Part-of-speech tagging and dependency parsing are common applications of syntactic analysis,
where they identify the nouns, verbs, pronouns, and other elements in the text 
and how these elements relate, respectively. 
As an example of a syntactic analysis study in natural language software artifacts, 
Ko and colleagues identified regularities in the syntactic structure of the text 
of nearly 200,000 bug report titles~\cite{Ko2006}, suggesting that these 
regularities could be used for the automatic identification 
of information in bug reports. 






Sentences with similar terms or similar syntactic structure might convey different information
and researchers have also investigated the meaning of the text in natural language software artifacts. 
These studies consider the semantic analysis of the text and 
software engineering researchers have proposed \textit{taxonomies} to explain the type of information 
available in certain kinds of natural language artifacts~\cite{Maalej2013, Arya2019}. 
For example, Di Sorbo et al. have found that 
text in development mailing lists can be classified according to the developers' intentions (e.g., feature request, solution proposal, etc.)~\cite{Sorbo2015},
suggesting that one can automate this classification to assist developers in finding 
certain types of information.




Most of the textual analysis in related literature reveal similar trends, i.e., 
that there are regularities in the natural language text and that it might be possible 
to automatically identify such text. Nonetheless, 
existing studies focus on the text of a specific 
type of artifact and investigating if whether these regularities 
apply to different kinds of artifacts is still an open question. 
As a first step to investigate this question, 
Chapter~\ref{ch:characterizing}
presents an empirical study that investigates 
the text that developers 
deemed relevant to a software task 
in different kinds of artifact.


