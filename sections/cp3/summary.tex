\section{Summary}
\label{cp3:summary}



In this chapter, we address the problem of locating relevant information
to a particular software development task \textit{within} a natural language artifact.
To better understand how relevant information is encoded in natural language artifacts,
we detailed an empirical study investigating what text is perceived as relevant
and whether there is consistency in what 20 participants with software development experience deem relevant
to a particular software development task.


Our study comprised the analysis of a set of 20 artifacts originating from API documentation, bug reports, and Q\&A documents.
We observe that finding task-relevant information in such artifacts requires filtering to less than
a 20\% of the documents' text and that there is substantial variability in what information participants perceive as relevant.
Nonetheless, there are commonalities shared through most of the identified relevant textual pieces.
These commonalities are found in the semantic meanings extracted from the text suggesting that
the semantics of natural language artifacts might 
can be used in automatic approaches for 
automatically identifying task-relevant text.
